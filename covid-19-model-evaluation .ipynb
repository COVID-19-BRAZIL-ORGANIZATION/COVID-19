{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install Orange3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n# import category encoders\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import precision_score\nfrom sklearn import metrics\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.datasets import make_classification\nimport xgboost as xgb\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom mlxtend.evaluate import paired_ttest_5x2cv\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom scipy import stats as stats\nfrom scipy.stats import rankdata\nfrom sklearn.linear_model import LogisticRegression\n#from orange3.evaluation import compute_CD, graph_ranks\nimport Orange as ora\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/covid19final-dataset/both_test_unbalanced.csv\n/kaggle/input/covid19final-dataset/pcr_unbalanced.csv\n/kaggle/input/covid19final-dataset/rapid_balanced.csv\n/kaggle/input/covid19final-dataset/both_test_balanced.csv\n/kaggle/input/covid19final-dataset/rapid_unbalanced.csv\n/kaggle/input/covid19final-dataset/pcr_balanced.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Comparing multiple classifiers over multiple datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#balanced data\ndata_rapid = pd.read_csv(\"/kaggle/input/covid19final-dataset/rapid_balanced.csv\")\ndata_rapid=data_rapid.astype(int)\n\ndata_pcr= pd.read_csv(\"/kaggle/input/covid19final-dataset/pcr_balanced.csv\")\ndata_pcr=data_pcr.astype(int)\n\ndata_both= pd.read_csv(\"/kaggle/input/covid19final-dataset/both_test_balanced.csv\")\ndata_both=data_both.astype(int)\n\n\n#unbalanced data\ndata_rapid_unb = pd.read_csv(\"/kaggle/input/covid19final-dataset/rapid_unbalanced.csv\")\ndata_rapid_unb=data_rapid_unb.astype(int)\n\n\ndata_pcr_unb= pd.read_csv(\"/kaggle/input/covid19final-dataset/pcr_unbalanced.csv\")\ndata_pcr_unb=data_pcr_unb.astype(int)\n\n\nboth_data_unb = pd.read_csv(\"/kaggle/input/covid19final-dataset/both_test_unbalanced.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RandomForest_classif(x_train,y_train,param):\n    #Classification\n    \n    \n    clf= RandomForestClassifier(**param)\n    clf=clf.fit(x_train, y_train)\n    \n    return clf\n\ndef Kneighbors_classif(x_train,y_train,param):\n    #Classification\n    \n\n    clf= KNeighborsClassifier(**param)\n    clf= clf.fit(x_train, y_train)\n\n    return clf\n\ndef DecisionTree_classif(x_train,y_train,param):\n    #Classification\n    \n    clf = tree.DecisionTreeClassifier(**param)\n    clf = clf.fit(x_train,y_train)\n    \n    return clf\n\ndef mpl_classif(x_train,y_train,param):\n    \n    clf =  MLPClassifier(**param)\n    clf=clf.fit(x_train,y_train)\n    \n    return clf\n\ndef gb_classif(x_train,y_train,param):\n    \n    clf=GradientBoostingClassifier(**param)\n    clf=clf.fit(x_train, y_train)\n    \n    return clf\n\ndef xgb_classif(x_train,y_train,param):\n    clf = xgb.XGBClassifier(**param)\n    \n    return clf.fit(x_train, y_train)\n\ndef svc_classif(x_train,y_train,param):\n    \n    regr = svm.SVC(**param)\n    regr=regr.fit(x_train, y_train)\n    \n    return regr\n\ndef lg_with_regu_classif(x_train,y_train,param):\n    \n    clf = LogisticRegression(** param)\n    clf=clf.fit(x_train,y_train)\n    \n    return clf\ndef lg_without_regu_classif(x_train,y_train,param):\n    \n    clf = LogisticRegression(** param)\n    clf=clf.fit(x_train,y_train)\n   \n    return clf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_metrics(x_train, x_test,y_train, y_test,clf):\n    \n        #prediction\n        y_pred=clf.predict(x_test)\n        \n        \n        #confusion matrix\n        tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n        \n        \n        #recall\n        recall=(tp/(tp+fn))*100\n        \n        \n        return recall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def k_fold_cross_validation(x,y,lista_param):\n    dt=pd.DataFrame(columns=['DT','RF','GBM','XGBoost','Mlp','SVM','KNN','LRR','LRR'],index=range(50))\n    \n    kf=RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=42)\n                        \n    \n    kf.get_n_splits(x,y)\n    k=0\n    for train_index, test_index in kf.split(x,y):\n\n        x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        \n        clf_dt=DecisionTree_classif(x_train,y_train,lista_param[0])\n        dt.iloc[k:k+1,:1]=calculate_metrics(x_train, x_test,y_train, y_test,clf_dt)\n        \n        clf_rf=RandomForest_classif(x_train,y_train,lista_param[1])\n        dt.iloc[k:k+1,1:2]=calculate_metrics(x_train, x_test,y_train, y_test,clf_rf)\n        \n        clf_svm=svc_classif(x_train,y_train,lista_param[2])\n        dt.iloc[k:k+1,5:6]=calculate_metrics(x_train, x_test,y_train, y_test,clf_svm)\n       \n        clf_knn=Kneighbors_classif(x_train,y_train,lista_param[3])\n        dt.iloc[k:k+1,6:7]=calculate_metrics(x_train, x_test,y_train, y_test,clf_knn)\n        \n        clf_gbm=gb_classif(x_train,y_train,lista_param[4])\n        dt.iloc[k:k+1,2:3]=calculate_metrics(x_train, x_test,y_train, y_test,clf_gbm)\n        \n        clf_lg_regu=lg_with_regu_classif(x_train,y_train,lista_param[5])\n        dt.iloc[k:k+1,7:8]=calculate_metrics(x_train, x_test,y_train, y_test,clf_lg_regu)\n        \n        clf_lg=lg_without_regu_classif(x_train,y_train,lista_param[6])\n        dt.iloc[k:k+1,8:9]=calculate_metrics(x_train, x_test,y_train, y_test,clf_lg)\n        \n        clf_mlp=mpl_classif(x_train,y_train,lista_param[7])\n        dt.iloc[k:k+1,4:5]=calculate_metrics(x_train, x_test,y_train, y_test,clf_mlp)\n        \n        clf_xgboost=xgb_classif(x_train,y_train,lista_param[8])\n        dt.iloc[k:k+1,3:4]=calculate_metrics(x_train, x_test,y_train, y_test,clf_xgboost)\n        print(k)\n        k+=1\n        \n        \n        \n    return  dt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_performace(dt):\n    # Then, we extract the performances as a numpy.ndarray.\n    performances_array =  dt.iloc[:,:].values\n    algorithms_names=dt.columns.values\n    # Finally, we apply the Friedman test.\n    t, p =stats.friedmanchisquare(*performances_array)\n    # summarize\n    print('P-value:' , p, 't-Statistic: %.3f' % (t))\n    # interpret the result\n    if p <= 0.1:\n        print('Difference between mean performance is probably real')\n    else:\n        print('Algorithms probably have the same performance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_average_ranks(dt):\n    performances_array =  dt.iloc[:,:].values\n    algorithms_names=dt.columns.values\n    # Calculating the ranks of the algorithms for each dataset. The value of p is multipled by -1\n    # because the rankdata method ranks from the smallest to the greatest performance values.\n    # Since we are considering Recall as our performance measure, we want larger values to be best ranked.\n    ranks = np.array([rankdata(-p) for p in performances_array])\n    # Calculating the average ranks.\n    average_ranks = np.mean(ranks, axis=0)\n    print('\\n'.join('{} average rank: {}'.format(a, r) for a, r in zip(algorithms_names, average_ranks)))\n    return average_ranks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_critical_difference(dt,average_ranks,name):\n    # This method computes the critical difference for Nemenyi test with alpha=0.1.\n    # For some reason, this method only accepts alpha='0.05' or alpha='0.1'.\n    algorithms_names=dt.columns.values\n    cd =  ora.evaluation.compute_CD(average_ranks,\n    n=len(dt),\n    alpha='0.1',\n    test='nemenyi')\n    # This method generates the plot.\n    ora.evaluation.graph_ranks(average_ranks,\n    names=algorithms_names,\n    cd=cd,\n    width=10,\n    textspace=1.5,\n    reverse=True)\n    plt.savefig(name)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# rapid balanced test"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlista_param=[\n             {},\n             {},\n             {'kernel': 'rbf', 'C': 6,'probability':True},\n             {'weights': 'distance', 'n_neighbors': 15,'n_jobs': None, 'leaf_size': 5, 'algorithm': 'ball_tree'},\n             {'n_estimators':500,'max_depth':5},\n             {'solver': 'liblinear', 'penalty': 'l2','C': 0.1},\n             {'solver': 'liblinear', 'penalty': 'l2','C': 1.0},\n             {'solver': 'adam', 'random_state': 1, 'max_iter': 1200, 'learning_rate': 'adaptive','alpha': 0.0001, 'activation': 'relu'},\n             {'n_estimators':300,'max_depth':9,'min_child_weight': 2}]\n\nd_rapid=k_fold_cross_validation(data_rapid.iloc[:,0:10],data_rapid['Class'],lista_param) \n\nmean_performace(d_rapid)\nd_rapid_average_ranks=calculate_average_ranks(d_rapid)\nplot_critical_difference(d_rapid,d_rapid_average_ranks,'model_evaluation_rapid_balanced.jpg')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# This method computes the critical difference for Bonferroni-Dunn test with alpha=0.1.\n# For some reason, this method only accepts alpha='0.05' or alpha='0.1'.\ncd = ora.evaluation.compute_CD(average_ranks,\nn=len(dt),\nalpha='0.1',\ntest='bonferroni-dunn')\n# This method generates the plot.\nora.evaluation.graph_ranks(average_ranks,\nnames=algorithms_names,\ncd=cd,\ncdmethod=0,\nwidth=10,\ntextspace=1.5,\nreverse=True)\nplt.show()\n"},{"metadata":{},"cell_type":"markdown","source":"# rapid unbalanced test"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nlista_param=[\n{},\n{},\n{'kernel': 'rbf', 'C': 11,'probability':True},\n{'weights': 'distance', 'n_neighbors': 5, 'n_jobs': None, 'leaf_size': 3, 'algorithm': 'kd_tree'},\n{'n_estimators':500,'max_depth':5},\n{'solver': 'saga', 'penalty': 'l2', 'max_iter': 1200, 'C': 0.1},\n{'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 400, 'C': 4.0},\n{'max_iter': 1800,'solver':'lbfgs', 'alpha':1e-5, 'random_state':42},\n{'n_estimators':300,'max_depth':9,'min_child_weight': 2}]          \n\nd_rapid_unb=k_fold_cross_validation(data_rapid_unb.iloc[:,0:10],data_rapid_unb['Class'],lista_param) \n\nmean_performace(d_rapid_unb)\nd_rapid_unb_average_ranks=calculate_average_ranks(d_rapid_unb)\nplot_critical_difference(d_rapid_unb,d_rapid_unb_average_ranks,'model_evaluation_rapid_unbalanced.jpg')\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# pcr balanced test"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nlista_param=[\n{},\n{},\n{'kernel': 'rbf', 'C': 7,'probability':True},\n{'weights': 'distance', 'n_neighbors': 5, 'n_jobs': None, 'leaf_size': 3, 'algorithm': 'kd_tree'},\n{'n_estimators':500,'max_depth':5},\n{'solver': 'liblinear', 'penalty': 'l2','C': 0.1},\n{'solver': 'liblinear', 'penalty': 'l2','C': 1.0},\n{'max_iter': 1800,'solver':'lbfgs', 'alpha':1e-5, 'random_state':42},\n{'n_estimators':300,'max_depth':9,'min_child_weight': 2}]\n\npcr_bal=k_fold_cross_validation(data_pcr.iloc[:,0:10],data_pcr['Class'],lista_param) \n\nmean_performace(pcr_bal)\nd_pcr_bal_average_ranks=calculate_average_ranks(pcr_bal)\nplot_critical_difference(pcr_bal,d_pcr_bal_average_ranks,'model_evaluation_pcr_balanced.jpg')\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# pcr unbalanced test"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nlista_param=[\n{},\n{},\n{'kernel': 'rbf', 'C': 6,'probability':True},\n{'weights': 'distance', 'n_neighbors': 8, 'n_jobs': -1, 'leaf_size': 2, 'algorithm': 'auto'},\n{'n_estimators':500,'max_depth':5},\n{'solver': 'liblinear', 'penalty': 'l2','C': 0.1},\n{'solver': 'liblinear', 'penalty': 'l2','C': 1.0},\n{'max_iter': 1800,'solver':'lbfgs', 'alpha':1e-5, 'random_state':42},\n{'n_estimators':300,'max_depth':9,'min_child_weight': 2}]\n\npcr_unb=k_fold_cross_validation(data_pcr_unb.iloc[:,0:10],data_pcr_unb['Class'],lista_param) \n\nmean_performace(pcr_unb)\nd_pcr_unb_average_ranks=calculate_average_ranks(pcr_unb)\nplot_critical_difference(pcr_unb,d_pcr_unb_average_ranks,'model_evaluation_pcr_unbalanced.jpg')\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# both balanced test"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nlista_param=[{},{},{'kernel': 'rbf', 'C': 9,'probability':True},\n             {'weights': 'distance','n_neighbors': 8, 'n_jobs': -1,'leaf_size': 5, 'algorithm': 'brute'},\n             {'n_estimators':500,'max_depth':5},\n             {'solver': 'liblinear', 'penalty': 'l2','C': 0.1},\n             {'solver': 'liblinear', 'penalty': 'l2','C': 1.0},\n             {'max_iter': 1200,'solver':'lbfgs', 'alpha':1e-5, 'random_state':42},\n            {'n_estimators':300,'max_depth':9,'min_child_weight': 2}]\n\n\nboth_test=k_fold_cross_validation(data_both.iloc[:,0:10],data_both['Class'],lista_param) \n\nmean_performace(both_test)\nboth_test_average_ranks=calculate_average_ranks(both_test)\nplot_critical_difference(both_test,both_test_average_ranks,'model_evaluation_bothtest_balanced.jpg')\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# both unbalanced test"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nlista_param=[{},{},{'kernel': 'rbf', 'C': 8,'probability':True},\n             {'n_neighbors': 15},\n             {'n_estimators':500,'max_depth':5},\n             {'solver': 'liblinear', 'penalty': 'l2','C': 0.1},\n             {'solver': 'liblinear', 'penalty': 'l2','C': 1.0},\n             {'max_iter': 1800,'solver':'lbfgs', 'alpha':1e-5, 'random_state':42},\n            {'n_estimators':300,'max_depth':9,'min_child_weight': 2}]\n\n\nboth_test_unb=k_fold_cross_validation(both_data_unb.iloc[:,0:10],both_data_unb['Class'],lista_param) \n\nmean_performace(both_test_unb)\nboth_test_unb_average_ranks=calculate_average_ranks(both_test_unb)\nplot_critical_difference(both_test_unb,both_test_unb_average_ranks,'model_evaluation_bothtest_unbalanced.jpg')\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}