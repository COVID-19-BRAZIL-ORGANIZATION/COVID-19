{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install Orange3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n# import category encoders\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import precision_score\nfrom sklearn import metrics\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.datasets import make_classification\nimport xgboost as xgb\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom mlxtend.evaluate import paired_ttest_5x2cv\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom scipy import stats as stats\nfrom scipy.stats import rankdata\n#from orange3.evaluation import compute_CD, graph_ranks\nimport Orange as ora\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparing multiple classifiers over multiple datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_antibody = pd.read_csv(\"/kaggle/input/data-antibody/data_antibody.csv\")\ndata_antibody=data_antibody.astype(int)\ndata_pcr= pd.read_csv(\"/kaggle/input/pcr-data/pcr_data.csv\")\ndata_pcr=data_pcr.astype(int)\ndata_both= pd.read_csv(\"/kaggle/input/both-covid-data/both_covid_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RandomForest_classif(x_train,y_train):\n    #Classification\n    clf= RandomForestClassifier()\n    clf=clf.fit(x_train, y_train)\n    return clf\n\ndef Kneighbors_classif(x_train,y_train):\n    #Classification\n    clf= KNeighborsClassifier(n_neighbors=3)\n    clf= clf.fit(x_train, y_train)\n    return clf\n\ndef DecisionTree_classif(x_train,y_train):\n    #Classification\n    clf = tree.DecisionTreeClassifier()\n    clf = clf.fit(x_train,y_train)\n    return clf\n\ndef mpl_classif(x_train,y_train):\n    clf =  MLPClassifier(max_iter=300,solver='lbfgs', alpha=1e-5, random_state=42)\n    clf=clf.fit(x_train,y_train)\n    return clf\n\ndef gb_classif(x_train,y_train):\n    param_dist = {'n_estimators':500,'max_depth':5}\n    clf=GradientBoostingClassifier(**param_dist)\n    clf=clf.fit(x_train, y_train)\n    return clf\n\ndef xgb_classif(x_train,y_train):\n    param_dist = {'n_estimators':300,'max_depth':9,'min_child_weight': 2}\n\n    clf = xgb.XGBClassifier(**param_dist)\n\n    return clf.fit(x_train, y_train)\n\ndef svc_classif(x_train,y_train):\n    regr = svm.SVC()\n    regr=regr.fit(x_train, y_train)\n    return regr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_metrics(x_train, x_test,y_train, y_test,clf):\n    \n        #prediction\n        y_pred=clf.predict(x_test)\n        \n        #accuracy score\n        #acc=accuracy_score(y_test,y_pred)*100\n        \n        #confusion matrix\n        tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n        \n        \"\"\"\n        #precision\n        data.iloc[k:k+1,:1]=(tp/(tp+fp))*100\n         \n        data.iloc[k:k+1,1:2]=acc\n        \"\"\"\n        #recall\n        recall=(tp/(tp+fn))*100\n        \n        \n        return recall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_prediction(x,y):\n   \n    dt=pd.DataFrame(columns=['DT','RF','GBM','XGBoost','Mlp','SVM','KNN'],index=range(50))\n    \n\n    n=0\n    for k in range(50):\n\n        x_train, x_test, y_train, y_test = train_test_split(\n        x, y, test_size=0.3,random_state=n,stratify=y)\n        \n        clf_svm=svc_classif(x_train,y_train)\n        dt.iloc[k:k+1,5:6]=calculate_metrics(x_train, x_test,y_train, y_test,clf_svm)\n        \n        \n        clf_knn=Kneighbors_classif(x_train,y_train)\n        dt.iloc[k:k+1,6:]=calculate_metrics(x_train, x_test,y_train, y_test,clf_knn)\n        \n        clf_dt=DecisionTree_classif(x_train,y_train)\n        dt.iloc[k:k+1,:1]=calculate_metrics(x_train, x_test,y_train, y_test,clf_dt)\n        \n        clf_rf=RandomForest_classif(x_train,y_train)\n        dt.iloc[k:k+1,1:2]=calculate_metrics(x_train, x_test,y_train, y_test,clf_rf)\n        \n        clf_mlp=mpl_classif(x_train,y_train)\n        dt.iloc[k:k+1,4:5]=calculate_metrics(x_train, x_test,y_train, y_test,clf_mlp)\n        \n        clf_gbm=gb_classif(x_train,y_train)\n        dt.iloc[k:k+1,2:3]=calculate_metrics(x_train, x_test,y_train, y_test,clf_gbm)\n        \n        clf_xgboost=xgb_classif(x_train,y_train)\n        dt.iloc[k:k+1,3:4]=calculate_metrics(x_train, x_test,y_train, y_test,clf_xgboost)\n        \n        n+=1\n    \n    \n    return dt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt=calculate_prediction(data_both.iloc[:,0:10],data_both['Class'])\ndt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Then, we extract the performances as a numpy.ndarray.\nperformances_array =  dt.iloc[:,:].values\nalgorithms_names=dt.columns.values\n# Finally, we apply the Friedman test.\nt, p =stats.friedmanchisquare(*performances_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize\nprint('P-value:' , p, 't-Statistic: %.3f' % (t))\n# interpret the result\nif p <= 0.1:\n    print('Difference between mean performance is probably real')\nelse:\n    print('Algorithms probably have the same performance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating the ranks of the algorithms for each dataset. The value of p is multipled by -1\n# because the rankdata method ranks from the smallest to the greatest performance values.\n# Since we are considering Recall as our performance measure, we want larger values to be best ranked.\nranks = np.array([rankdata(-p) for p in performances_array])\n# Calculating the average ranks.\naverage_ranks = np.mean(ranks, axis=0)\nprint('\\n'.join('{} average rank: {}'.format(a, r) for a, r in zip(algorithms_names, average_ranks)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This method computes the critical difference for Nemenyi test with alpha=0.1.\n# For some reason, this method only accepts alpha='0.05' or alpha='0.1'.\ncd =  ora.evaluation.compute_CD(average_ranks,\nn=len(dt),\nalpha='0.1',\ntest='nemenyi')\n# This method generates the plot.\nora.evaluation.graph_ranks(average_ranks,\nnames=algorithms_names,\ncd=cd,\nwidth=10,\ntextspace=1.5,\nreverse=True)\nplt.savefig('model_evaluation.jpg')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This method computes the critical difference for Bonferroni-Dunn test with alpha=0.1.\n# For some reason, this method only accepts alpha='0.05' or alpha='0.1'.\ncd = ora.evaluation.compute_CD(average_ranks,\nn=len(dt),\nalpha='0.1',\ntest='bonferroni-dunn')\n# This method generates the plot.\nora.evaluation.graph_ranks(average_ranks,\nnames=algorithms_names,\ncd=cd,\ncdmethod=0,\nwidth=10,\ntextspace=1.5,\nreverse=True)\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}